%
% NOTE -- ONLY EDIT bayespeak.rnw!!!
%
%\VignetteIndexEntry{BayesPeak Vignette}
%\VignetteDepends{}
%\VignetteKeywords{BayesPeak}
%\VignettePackage{BayesPeak}
\documentclass{article}

\usepackage{hyperref}
\usepackage{Sweave}
\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}

\SweaveOpts{keep.source=TRUE} 

\newcommand{\classdef}[1]{
  {\em #1}
}
\begin{document}
\title{\Rpackage{BayesPeak}: Bayesian Analysis of ChIP-seq data}

\author{Jonathan Cairns}

\maketitle

\textbf{Warning}: This is an early version of BayesPeak and is still in development, if you encounter any problems please send an email to 
\textit{jonathan.cairns@cancer.org.uk}. Please read section 6 to avoid the overfitting effect that may negatively impact your analysis. 


%\section*{Note to package reviewers}

%There are a number of things I would like to do with \Rpackage{BayesPeak} to make it easier to use and better align it with Bioconductor workflows. But at the same time, I would like to make this package available to those who wish to use it at first opportunity.

%The following are known issues/improvements:

%\begin{itemize}
%\item Rework structure of package to deal with data entirely in IRanges format. Control data may benefit from Rle object (treatment almost certainly will not.)
%\item Convert all functions to S4 methods and change the raw.output object into a class.
%\item Parallelisation: I want to keep memory down for obvious reasons. If we perform the binning step on the entire genome in one go, this would take up more memory but allow us to better use processor time. Need to investigate whether the tradeoff is worthwhile.
%\item Is there a memory leak? There seems to be, but the code looks fine to me and my colleagues.
%\item Add clever function for taking a particular job, plotting a histogram of the input data in the region, marking the bins that have been called as enriched.
%\item Better support for the overfitting ``bug''. What is the ``best'' way to deal with this problem?
%\item Models for other data types, multiple replicates, etc...
%\end{itemize}

\section*{Introduction}

\Rpackage{BayesPeak} is a Bioconductor package for the analysis of data sets from ChIP-seq style experiments, particularly for identifying the genomic sites of interest.

The algorithm models the positions and orientations of the sequenced fragments and determines the locations of enriched areas, such as binding sites and histone modifications, by using hidden Markov models and Bayesian statistical methodology.

The Bayesian approach to parameter and state estimation returns posterior probabilities as measure of certainty, which offers great scope for interpretation, as well as allowing for the use of these probabilities as weights in subsequent analyses (e.g. motif discovery).

The other important feature of the model is the use of the negative binomial distribution to model the counts of sequenced reads. This allows for overdispersion and provides a better fit to the data than the Poisson distribution that has been widely used by other methods. 

\section{What is ChIP-seq?}
Chromatin Immunoprecipitation (ChIP) is an experiment designed to study protein-DNA interactions, particularly to identify the genomic sites where proteins, such as transcription factors, bind to the DNA and where histone modifications occur. The procedure produces samples that are enriched for the sites of interest compared to the rest of the genome. The use of this method combined with high-throughput sequencing of the samples is referred to as ChIP-seq. 

 Given our protein of interest, the ChIP-seq protocol usually consists of the following steps. (The exact protocol may vary between different experiments, but \Rpackage{BayesPeak} will still be able to perform the peak-calling step.)
	\begin{itemize}
		\item Cross-linking the proteins to the DNA - The protein is permanently bound to the DNA, usually with formaldehyde.
		\item Shearing - The cells are lysed, and the DNA is randomly cut into small fragments by sonication.
		\item Immunoprecipitation - An antibody specific to the protein of interest is used to isolate the protein and the attached DNA fragments. The resulting sample is enriched for those genomic regions.
		\item Reverse crosslinking and purification - The bonds between the protein and DNA are broken. The DNA is subsequently purified.
		\item Sequencing - During library preparation the contents of the samples are size selected such that the fragments' length lies in the region of 200-300 bp. This step is required by the sequencing protocol.  Adaptors are attached to the fragments and amplification usually takes place.
Subsequently, the sample undergoes "high-throughput sequencing" during which the sequence of the ends of the present fragments is identified. For ChIP-seq applications usually one end of the fragments is sequenced to produce "single-end" reads.
		\item Alignment - The DNA is aligned back to reference genome, taking the quality of the reads into account. Usually only the reads that map to unique locations in the genome are included in the downstream analysis.
		\item Analysis - The sites of interest correspond to the genomic regions where there is high abundance of reads compared to the background or the control sample. \Rpackage{BayesPeak} performs this identification step, also referred to as ``peak-calling".
	\end{itemize}

ChIP-seq can be used to find histones with a certain epigenetic modification. In this case, we use an antibody specific to histones with that modification.

There are many sources of error - for example, misalignment, impurities, or DNA which simply has a high affinity for being sequenced - which can result in noise across the genome, or even false peaks. The \Rpackage{BayesPeak} model is designed to separate the peaks from the noise, and to avoid calling false peaks.

\section{Simple workflow}

Load the package as follows:

<<>>=
library(BayesPeak)
@

The example data set used below, consisting of the files ``H3K4me3-chr16.bed" and ``Input-chr16.bed", can be downloaded from \texttt{http://www.compbio.group.cam.ac.uk/Resources/BayesPeak/csbayespeak.html}.

The following code is a very simple example of a \Rpackage{BayesPeak} workflow, where we analyse the region 92,000,000 - 95,000,000 on chromosome 16. It should take a couple of minutes on a relatively modern machine.

<<ex1, eval=FALSE>>=
raw.output <- bayespeak("H3K4me3-chr16.bed", "Input-chr16.bed",
			chr = "chr16", start = 9.2E7, end = 9.5E7)
output <- summarise.peaks(raw.output, method = "lowerbound")
@

\begin{itemize}
\item bayespeak() runs the actual BayesPeak algorithm on the data. The two input files are bed files located in the working directory, with H3K4me3 being the IP-treated data set and Input ID being the control data. In each case, we could have provided a data.frame or a RangedData object (from the IRanges package) instead of a file path. The function applies the algorithm to 6Mb partitions of the genome (or ``jobs"), as explained in section \ref{algorithm}.
\item raw.output is a list - it contains not only the bins called, but also some useful QC information (such as the model fit - in particular, this can be used to spot unreliable jobs as described in section \ref{overfitting}). This output needs to be summarised.
\item summarise.peaks is used to summarise the raw.output object. This consolidates the raw bin calls into peaks and combines data across jobs.
\end{itemize}

We can analyse all of the data present in the .bed file with the following command, although this will take somewhat longer. A parallelisation strategy is available to reduce this time, which is given in section \ref{MC}).
<<ex2, eval=FALSE>>=
raw.output <- bayespeak("H3K4me3-chr16.bed", "Input-chr16.bed")
output <- summarise.peaks(raw.output, method = "lowerbound")
@

We now go into this workflow in more depth.


\section{The algorithm}
\label{algorithm}

\Rpackage{BayesPeak} fits a Markov model to the data (the aligned reads) via Markov Chain Monte Carlo techniques.

The genome is firstly divided up into ``jobs", i.e. short regions, by default of size 6Mb, on which the algorithm is run independently. This allows us to account for the variation in read abundance across each chromosome.

Within a job, we divide the region into small bins (by default, 100 bases each), and we consider the number of reads whose starts lie within each bin, for each strand.

A hidden Markov model is fitted to the bins, thereby classifying them as enriched or unenriched for sites of interest. However, since the parameters of the model are unknown (for example, the mean number of counts within enriched or unenriched bins), we estimate them using Gibbs Sampling.

The output of the algorithm is the Posterior Probability (often abbreviated to ``PP") of each bin being enriched. The PP value is useful not only for calling the peaks, but could also be used in downstream analysis - for example, when finding a transcription factor motif, the PP could be used to weight observations. The PP value is not to be confused with the P value from hypothesis testing.

For a full explanation of the mathematics of the model, please refer to the paper given in section \ref{cite}.

\section{The bayespeak function}

The bayespeak function performs the algorithm described above on two sets of data - treatment, and control (optional), which should be supplied in bed format. Each of these can be specified as a file location, a data.frame containing the columns ``chr", ``start", ``end", ``strand" (``+"/``-"), or a RangedData object. For example:

<<Help, eval=FALSE>>=
raw.output <- bayespeak("H3K4me3-chr16.bed", "Input-chr16.bed")
@

%which will give the same results as:

%<<Help, eval=FALSE>>=
%H3K4 <- read.bed("H3K4me3-chr16.bed")
%Input <- read.bed("Input-chr16.bed")
%raw.output <- bayespeak(treatment = H3K4, control = Input)
%@

To account for the variability of conditions across the chromosome, we break down the chromosome into ``jobs", which by default are of length 6Mb, and run the algorithm on each job. Thus, each job has its own set of associated parameters.

To avoid missing any peaks that straddle a boundary between two bins, we run the algorithm a second time with the boundaries offset by half a window length. This second job is described as ``offset".

The output of this function is a list of three things:

\begin{itemize}
\item \$peaks: Locations of ``potentially enriched" bins, with their associated posterior probabilities. (A ``potentially enriched" bin is defined as any bin with PP > 0.01.)
\item \$QC: Information about the individual jobs.
\item \$call: A record of the arguments used when the function was called.
\end{itemize}

\subsection{Parallelising \Rpackage{BayesPeak} - use of the multicore package}
\label{MC}

Due to its computational intensity, \Rpackage{BayesPeak} can be slow. However, the jobs can be run in parallel. This allows us to take advantage of multiple processors and dramatically reduce the time the algorithm takes.

This feature requires the \Rpackage{multicore} package to be installed. At time of writing, it can be downloaded from \texttt{http://www.rforge.net/multicore/}.

Having installed multicore, you can run the bayespeak() function in parallel by using the use.multicore = TRUE option. You can override the number of cores that multicore uses with the mc.cores argument.

<<Help, eval=FALSE>>=
raw.output <- bayespeak("H3K4me3-chr16.bed", "Input-chr16.bed", use.multicore = TRUE, mc.cores = 4)
output <- combine.peaks(raw.output, method = "lowerbound")
@


\section{The summarise.peaks function}

bayespeak() returns, as raw output, the details of all of the individual bins in each individual job, which is somewhat verbose. We need to combine the output of the jobs, and combine enriched bins into contiguous regions, which will be our final called peaks. This task is performed by the summarise.peaks() function.

In more detail, summarise.peaks() does the following:
\begin{itemize}
\item Remove unenriched jobs: When a job contains no enrichment, the model naturally tries to identify enriched states in the background. This can result in many unreliable calls for that job. We can remove all calls associated with such jobs. (This issue, ``overfitting", is described in detail in the next section, \ref{overfitting}.)
\item Threshold: Remove all bins whose PP values are below a certain value.
\item Collect bins: The bins across all remaining jobs are collected together. If two jobs call exactly the same bin, which could happen in regions where jobs overlap, then the one with the larger PP value is used.
\item Combine bins: Where a number of bins form a contiguous region, we combine them into one large peak. The large peak now is assigned a PP value, based on the PP values of its component bins. Combining the PP values from multiple bins may be done in several ways. As a default, the ``lowerbound" method is used, which calculates a lower bound for the overall PP by a dynamic programming technique. (See the help file for more information.)
\end{itemize}

\section{Choosing an appropriate threshold value}

Selecting the threshold for PP values (i.e. the threshold argument in summarise.peaks()) is an important step in the analysis, and its choice will greatly affect the peaks returned.

For high coverage data, peaks are clearer and thus the PP values of bins may converge to 0 or 1. In this case, the default value of 0.5 will suffice to distinguish between enrichment and unenrichment. However, when the coverage is less high, and we therefore have less information, the PP values will be spread over the interval [0,1]. In order to prevent bins from falsely being called, a judgement may need to be made as to what PP value constitutes enrichment. %%!!distinct from overfitting

To aid our choice, we can investigate the distribution of the PP values, as in the following code.

For this section, we load the example raw.output object included with the package:

<<PP1>>=
data(raw.output)
raw.output$call
@

As we can see, raw.output was generated from running bayespeak() with the above arguments. However, to save space, raw.output\$peaks has been manually reduced to only contain the data from chr16.

We observe the distribution of PP values across all of the bins present in raw.output:

<<PP2, fig = TRUE>>=
hist(raw.output$peaks$PP, breaks = 150)
threshold <- quantile(raw.output$peaks$PP, 0.85)
lines(x = rep(threshold,2), y= c(0,1000), col = "Red")
@

From this plot, we can choose an arbitrary PP value to use as a threshold. The red line on the plot shows the 85\% quantile, and should we decide on this value as a threshold, we can summarise as follows:

<<PP2b>>=
output <- summarise.peaks(raw.output, threshold)
@

%However, the distribution of PP values in the plot above appears somewhat multimodal. There is a possibility that this is due to distributions differing across jobs, and therefore we may wish to select different PP thresholds for each job.

%We can examine the PP values on a job-by-job basis with the following code:

%<<PP3, fig = FALSE>>=
%PP <- split(raw.output$peaks$PP, raw.output$peaks$job)
%par(mfrow = c(2,2), ask = T)
%for(i in 1:length(PP)) hist(PP[[i]], breaks =150, main = names(PP)[i])
%@

%<<PP3b, fig = TRUE, echo = FALSE>>= %%show only the last 4 plots of the above code
%par(mfrow = c(2,2))
%for(i in 25:28) hist(PP[[i]], breaks =150, main = names(PP)[i])
%@

%Note, for example, that job 342 is qualitatively different to jobs 341, 343 and 344 in its PP histogram. (This may be due to overfitting, for example - see section \ref{overfitting}.)



\section{Overfitting}
\label{overfitting}

\Rpackage{BayesPeak} can run into an overfitting problem when a job doesn't contain any peaks, or when peaks are weak compared to the background.

For this section, we again load the example raw.output object included with the package:

<<OF1>>=
data(raw.output)
@

The model assumes that there are both unenriched and enriched regions present. When the data contains no enriched regions, the model still tries to identify peaks in the data. Since some bins in the background will have higher counts than others, purely by chance, these will be marked as enriched.

%examples
\begin{figure}
  \begin{center}
    \includegraphics{OF.png}
  \end{center}
  \caption{An example of overfitting. Both of these graphs are histograms, where only reads on the positive strand are shown for clarity. A blue bar indicates that \Rpackage{BayesPeak} has called that bin as containing a peak at PP > 0.5. On the left, BayesPeak uses the enriched and unenriched states to explain the variance present in the background. On the right, the algorithm correctly identifies the large peaks present in the region of interest. (Notice the difference in scale between the two plots.)}
\end{figure}

%<<OF2>>=
%@


This effect will be reflected in the parameters of the model, since the expected number of reads allocated at ``enriched" regions will be much lower for the jobs where no peaks are present compared to the other jobs. This is one purpose of the QC component of the output - we can diagnose which peaks were called simply because they are in an unenriched job rather than because they are actual peaks.

Jobs suffering from this problem tend to exhibit three properties:
\begin{itemize}
\item Unusually large number of $calls$.
\item Small $\lambda_1$ (mean number of counts in an enriched bin)
\item PP values are spread out over the interval [0,1] rather than mostly being 0 or 1. We quantify this using a score: of the bins with PP values > 0.01, the score is the proportion that have PP > 0.5. A low score is therefore indicative of overfitting.
\end{itemize}

We can observe when overfitting has occured in our data set by plotting these properties against each other. Two clusters are visible in the plots below, one of which is a cluster of jobs suffering from overfitting.

<<OF3, fig = TRUE>>=
plot(log(raw.output$QC$calls), log(raw.output$QC$lambda1),
	main = "Job parameters - enriched bin counts against calls")
@
<<OF3b, fig = TRUE>>=
plot(log(raw.output$QC$calls), log(raw.output$QC$score),
	main = "Job paramaters - score against calls")
@

Some jobs are expected to show no enrichment throughout, such as the centromere, and the location of these regions can be taken into account at a later version of the algorithm. At the moment, our approach is to apply BayesPeak to the whole genome and subsequently to filter out peaks that are allocated within regions of no enrichment.

\subsection{Excluding calls from unenriched jobs}
We can choose to simply remove all calls from particular jobs. For example, having looked at the first of the two plots above, we can specify the overfit cluster by removing all jobs with low counts in their enriched bins - for example, $\log(\lambda_1) < 1.5$:

<<OF4>>=
unreliable.jobs <- log(raw.output$QC$lambda1) < 1.5
output.sj <- summarise.peaks(raw.output, method = "lowerbound", exclude.jobs = unreliable.jobs)
@

Alternatively, from looking at either plot, we could try to specify the overfit cluster better by adding jobs with excessive numbers of calls - $log(calls) > 5$. This gives us two selection criteria as follows:

<<OF5>>=
unreliable.jobs2 <- log(raw.output$QC$lambda1) < 1.5 | log(raw.output$QC$calls) > 5
output.sj2 <- summarise.peaks(raw.output, method = "lowerbound", exclude.jobs = unreliable.jobs2)
@

%%example

%\subsection{Choose a stronger prior}
%For the mathematically inclined, choosing a strong enough prior on $\lambda_0$, $\lambda_1$ may overcome this problem. Under the prior,
%$$\lambda_i \sim Gamma(\alpha_i,\beta_i)$$

%with

%$$\alpha_i \sim Gamma(\alpha_{\alpha_i}, \beta_{\alpha_i})$$
%$$\beta_i \sim Gamma(\beta_{\beta_i}, \beta_{\beta_i})$$

%Note that $\beta$ is always a scale parameter and not a rate parameter. You can specify a prior by specifying this vector:

%$$prior = \left(\alpha_{\alpha_0}, \beta_{\alpha_0}, \alpha_{\beta_0}, \beta_{\beta_0}, \alpha_{\alpha_1}, \beta_{\alpha_1}, \alpha_{\beta_1}, \beta_{\beta_1}\right)$$

%If the expectation of any of these variables is too small (i.e. $\alpha_?\beta_? < 0.0001$) then this will result in an error (this is to avoid division by 0 when Gibbs Sampling).

%<<Help, eval=FALSE>>=
%output <- bayespeak("H3K4me3-chr16.bed", "Input-chr16.bed", prior = c(5, 5, 10, 5, 25, 4, 0.5, 5))

%eps <- 1E-6
%output <- bayespeak("H3K4me3-chr16.bed", "Input-chr16.bed", prior = c(5, 5, 10, 5, 2.5/eps, eps, 0.25/eps, eps))
%output <- combine.peaks(output, method = "lowerbound")
%@
%In the second case, by making the variance of $\alpha_1$ and $\beta_1$ very small, we have essentially set: $$\lambda_1 \sim gamma(2.5, 0.25)$$



\section{Citing \Rpackage{BayesPeak}}
\label{cite}

\begin{flushleft}
If you use \Rpackage{BayesPeak} then please cite:\newline


Christiana Spyrou, Rory Stark, Andy Lynch and Simon Tavar\'{e} (2009). \emph{BayesPeak: Bayesian analysis of ChIP-seq data}, BMC Bioinformatics 2009, 10:299 doi:10.1186/1471-2105-10-299".



\end{flushleft}

%\section{Asking for help on \Rpackage{BayesPeak}}

%Wherever possible, please send all queries about \Rpackage{BayesPeak} to the
%Bioconductor mailing list at {\tt bioconductor@stat.math.ethz.ch}. This will
%help maintain a searchable archive of questions and responses.
%When posting to the list, please include the commands you used along with the
%version of \Rpackage{BayesPeak} and {\tt R} you are working with.
%Version information can be obtained by running the following command:

%<<Mailing list, eval=FALSE>>=
%sessionInfo()
%@

<<>>=
sessionInfo()
@

\section{Acknowledgements}

Many thanks to Dr. Duncan Odom's group for permission to use the H3K4me3 data set, and to Dr. Jason Carroll's group for permission to use the data set used in the raw.output data file.

\end{document}

